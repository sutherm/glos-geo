{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de74506-9484-4a5c-ade8-f4c649087b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import Polygon\n",
    "import h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b014632-b623-439e-87a8-7ffe0028dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def today():\n",
    "    \"\"\"\n",
    "    Create a string representing today's date, formatted for subsequent processing   \n",
    "    \n",
    "    Parameters:\n",
    "    None\n",
    "    \n",
    "    Returns:\n",
    "    String representing today's date in YYYY-mm-dd form \n",
    "    \"\"\"\n",
    "    \n",
    "    now = datetime.now()\n",
    "    now_str = now.strftime('%Y-%m-%d')\n",
    "    return now_str\n",
    "\n",
    "\n",
    "def csb_extents(shp):\n",
    "    \"\"\"\n",
    "    Create a formatted string representing the bounding extents to constrain CSB order\n",
    "    \n",
    "    Parameters:\n",
    "    shp (str): path to geospatial file (e.g. shapefile) defining spatial extents of search window\n",
    "    \n",
    "    Returns:\n",
    "    String representing bounding coordinates (min x, min y, max x, max y)\n",
    "    \n",
    "    See: https://github.com/CI-CMG/pointstore-api-docs/blob/main/pointstore_api.md for more info\n",
    "    \"\"\"\n",
    "    \n",
    "    gdf = gpd.read_file(shp)\n",
    "    bounds_string = ', '.join(map(str, gdf.total_bounds))\n",
    "    return bounds_string\n",
    "\n",
    "\n",
    "def csb_api_call(api_url, email, extents, startdate, stopdate):\n",
    "    \"\"\"\n",
    "    Make crowdsourced bathy API call to create DCDB data order  \n",
    "    \n",
    "    Parameters:\n",
    "    api_url (str): crowdsourced bathy point store URL\n",
    "    extents(str): coordinates defining spatial extent of search window (min x, min y, max x, max y)\n",
    "    startdate (str): beginning of temporal range to consider\n",
    "    stopdate (str): end of temporal range to consider\n",
    "    \n",
    "    Returns:\n",
    "    JSON response to the API call\n",
    "    \n",
    "    See: https://github.com/CI-CMG/pointstore-api-docs/blob/main/pointstore_api.md for more info\n",
    "    \"\"\"\n",
    "    \n",
    "    payload = {\n",
    "        \"email\": email,\n",
    "        \"bbox\": extents,\n",
    "        \"datasets\": [\n",
    "            {\n",
    "                \"label\": \"csb\",\n",
    "                \"collection_date\": {\"start\": startdate, \"end\": stopdate},\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Sending the POST request\n",
    "    response = requests.post(api_url, json=payload)\n",
    "\n",
    "    # Checking the response\n",
    "    if response.status_code == 201:\n",
    "        print(\"Success:\", response.json())\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "\n",
    "\n",
    "def api_call_status(order_id):\n",
    "    \"\"\"\n",
    "    Query status of DCDB CSB data order and extract path for data pickup  \n",
    "    \n",
    "    Parameters:\n",
    "    order_id (str): \n",
    "    \n",
    "    Returns:\n",
    "    String representing the ID of the crowdsourced bathy csv data file\n",
    "    \n",
    "    See: https://github.com/CI-CMG/pointstore-api-docs/blob/main/pointstore_api.md for more info\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(order_id)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        json_data = response.json()\n",
    "    \n",
    "        # Check if the status is \"complete\"\n",
    "        if json_data.get('status') == 'complete':\n",
    "            print(\"The response is complete.\")\n",
    "            csvname = json_data.get('output_location').split(\"/\")[-1]\n",
    "            return csvname #json_data.get('output_location')\n",
    "        else:\n",
    "            print(\"The response is not complete.\")\n",
    "    else:\n",
    "        print(f\"Error: Received status code {response.status_code}\")    \n",
    "    \n",
    "\n",
    "def create_csb_gdf(csb_file, meta_dict):\n",
    "    \"\"\"\n",
    "    Creates a geopandas dataframe containing h3 hex representations of csb sounding data and associated metadata \n",
    "    \n",
    "    Parameters:\n",
    "    csb_file (str): path to csv file containing csb data\n",
    "    meta_dict (str): python dictionary containing metadata that will be embedded in the geopandas dataframe\n",
    "    \n",
    "    Returns:\n",
    "    geopandas dataframe containing h3 geometries (level 11) and attribution \n",
    "    \"\"\"\n",
    "    # Read csv file and create pandas dataframe\n",
    "    df = pd.read_csv(csb_file)\n",
    "    \n",
    "    # Embed defined metadata and create h3 hexagon indices/geometry for each sounding\n",
    "    df['survey'] = meta_dict['survey']\n",
    "    df['surveyType'] = meta_dict['surveytype']\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df['surveyDate'] = df['time'].dt.strftime('%Y%m')\n",
    "    df['URL'] = meta_dict['url']\n",
    "    df.rename(columns={'provider': 'surveyOrg'}, inplace=True)\n",
    "    df['h3_index'] = df.apply(lambda row: h3.geo_to_h3(row['lat'], row['lon'], 11), axis=1)\n",
    "    df['geometry'] = df['h3_index'].apply(lambda h3_index: Polygon(h3.h3_to_geo_boundary(h3_index, geo_json=True)))\n",
    "    \n",
    "    # Convert pandas df to geopandas df\n",
    "    keep_cols = ['survey','surveyOrg','surveyDate', 'surveyType', 'URL', 'h3_index', 'geometry']\n",
    "    gdf = gpd.GeoDataFrame(df[keep_cols], geometry=df.geometry, crs=\"EPSG:4326\")\n",
    "        \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abb87ace-0781-4ef6-9f6d-5bb7bc736d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input variables\n",
    "shp = r\"/mnt/c/Users/mike/glos_data/test_extent.shp\"\n",
    "csb_api_url = \"https://q81rej0j12.execute-api.us-east-1.amazonaws.com/order\"\n",
    "email = \"glbathymetry@gmail.com\"\n",
    "bbox = csb_extents(shp)\n",
    "beg_d, end_d = \"2014-01-01\", today()\n",
    "csb_pickup_url = \"https://order-pickup.s3.amazonaws.com/\"\n",
    "metadata ={\"survey\": \"Crowdsourced Bathymetry\",\n",
    "           \"surveytype\": \"SBES\",\n",
    "           \"url\": \"https://www.ncei.noaa.gov/maps/iho_dcdb/\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b2e3fc9-5222-4891-a84a-2dfdbcc677b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: {'message': 'extract request 58289065-84ea-4154-900e-e8cf98a0a978 created.', 'url': 'https://q81rej0j12.execute-api.us-east-1.amazonaws.com/order/58289065-84ea-4154-900e-e8cf98a0a978'}\n"
     ]
    }
   ],
   "source": [
    "# Function calls to query DCDB for CSB data and create geopandas df\n",
    "csb = csb_api_call(csb_api_url, email, bbox, beg_d, end_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1abfc198-c691-4f0a-8da8-f9f10f020e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response is complete.\n"
     ]
    }
   ],
   "source": [
    "csb_csv = api_call_status(csb[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d2ebdb7-4a42-4db9-b6d0-0b03a6add0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csb_gdf = create_csb_gdf(os.path.join(csb_pickup_url, csb_csv), metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c41ddd-97e9-488b-8911-93cbf2c346f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group geopandas df by date (year-month)\n",
    "grouped = csb_gdf.groupby(['surveyDate'])\n",
    "\n",
    "# Iterate through array containing groups, remove duplicate records and write output geojson to disk\n",
    "for date, group in grouped:\n",
    "    # Remove duplicate rows\n",
    "    group = group.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # Create a filename\n",
    "    date_str = date[0]\n",
    "    filename = f\"/mnt/c/Users/mike/glos_data/ncei_csb/api_calls/testing/TEST_csb_output_{date_str}_level11.geojson\"\n",
    "        \n",
    "    # Write the group to a GeoJSON file\n",
    "    group.to_file(filename)\n",
    "\n",
    "    print(f\"Saved {filename} with {len(group)} records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72a720-3d7b-41c4-bde5-bad1e1cf4ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('h3_index').agg({\n",
    "    'depth': 'median'          # Count of dates (or you could use 'first', 'last', etc.)\n",
    "}).reset_index()\n",
    "grouped_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
